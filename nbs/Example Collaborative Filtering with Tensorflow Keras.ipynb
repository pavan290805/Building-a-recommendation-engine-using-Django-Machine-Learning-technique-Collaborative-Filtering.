{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering using Tensorflow & Keras\n",
    "In our [Recommender Course](https://www.codingforentrepreneurs.com/courses/recommender/) we build a Django-based recommendation engine leveraging the Surprise ML package (among other things). This guide is made to help you upgrade your ML package by leveraging Keras and a neural network. \n",
    "\n",
    "\n",
    "Recommended requirements for running this notebook:\n",
    "- GPU-accelerated / CUDA-enabled environment\n",
    "- Cloud-based service such as Google Colab, Deepnote, and/or Paperspace\n",
    "- [Recommender]((https://github.com/codingforentrepreneurs/recommender)) code forked/cloned/downloaded, open-source datasets loaded in, and Recommender models exported\n",
    "- To export the [Recommender](https://github.com/codingforentrepreneurs/recommender)'s datasets, you can run the functions `export_rating_dataset_task` and `export_movies_dataset_task` in the `exports/tasks.py`\n",
    "-  After you run these functions, you'll have the movies dataset located in `local-cdn/media/exports/movies/latest.csv` and the ratings dataset in `local-cdn/media/exports/ratings/latest.csv`\n",
    "\n",
    "\n",
    "\n",
    "This code was directly inspired and modified from the following posts:\n",
    "- [Fast.ai's Collaborative Filtering Lesson](https://course.fast.ai/Lessons/lesson7.html)\n",
    "- [How to create a Recommendation System from scratch using Keras from the Antonai Blog](https://antonai.blog/how-to-create-a-recommendation-system-from-scratch-using-keras/)\n",
    "- [Collaborative Filtering for Movie Recommendations the Keras Docs](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
    "\n",
    "\n",
    "### Open this notebook in...\n",
    "\n",
    "[<img src=\"https://deepnote.com/buttons/launch-in-deepnote-white-small.svg\">](https://deepnote.com/launch?url=https://github.com/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)\n",
    "\n",
    "[![Run on Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/codingforentrepreneurs/recommender/blob/main/src/nbs/Example%20Collaborative%20Filtering%20with%20Tensorflow%20Keras.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow sklearn matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:09.946362Z",
     "iopub.status.busy": "2022-09-21T17:06:09.946069Z",
     "iopub.status.idle": "2022-09-21T17:06:09.950651Z",
     "shell.execute_reply": "2022-09-21T17:06:09.950028Z",
     "shell.execute_reply.started": "2022-09-21T17:06:09.946342Z"
    },
    "id": "HCvzSnGbZKs4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:09.960324Z",
     "iopub.status.busy": "2022-09-21T17:06:09.960104Z",
     "iopub.status.idle": "2022-09-21T17:06:09.964650Z",
     "shell.execute_reply": "2022-09-21T17:06:09.964029Z",
     "shell.execute_reply.started": "2022-09-21T17:06:09.960307Z"
    }
   },
   "outputs": [],
   "source": [
    "# if using a cloud provider, upload your files to an \"exports folder\"\n",
    "# exports_dir = pathlib.Path().resolve() / 'exports' \n",
    "\n",
    "# if running this notebook from the root of the Recommender project\n",
    "exports_dir = pathlib.Path().resolve().parent / 'local-cdn' / 'media' / 'exports'\n",
    "\n",
    "movies_exports = exports_dir / 'movies' / 'latest.csv'\n",
    "ratings_exports = exports_dir / 'ratings' / 'latest.csv'\n",
    "print(movies_exports.exists(), ratings_exports.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:09.966139Z",
     "iopub.status.busy": "2022-09-21T17:06:09.965948Z",
     "iopub.status.idle": "2022-09-21T17:06:10.017754Z",
     "shell.execute_reply": "2022-09-21T17:06:10.016986Z",
     "shell.execute_reply.started": "2022-09-21T17:06:09.966124Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(movies_exports)\n",
    "\n",
    "# add a \"trend\" column to combine the count of ratings with the movie's average rating\n",
    "movies_df['trend'] = movies_df['rating_count'] * movies_df['rating_avg']\n",
    "movies_df['movieIdx'] = movies_df['movieIdx'].astype(int)\n",
    "movies_df['movieId'] = movies_df['movieId'].astype(int)\n",
    "\n",
    "print(movies_df.shape)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the entire ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.019295Z",
     "iopub.status.busy": "2022-09-21T17:06:10.019034Z",
     "iopub.status.idle": "2022-09-21T17:06:10.039846Z",
     "shell.execute_reply": "2022-09-21T17:06:10.039211Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.019273Z"
    }
   },
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv(ratings_exports)\n",
    "print(rating_df.shape)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the movies dataset and ratings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.040852Z",
     "iopub.status.busy": "2022-09-21T17:06:10.040662Z",
     "iopub.status.idle": "2022-09-21T17:06:10.074145Z",
     "shell.execute_reply": "2022-09-21T17:06:10.073404Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.040836Z"
    }
   },
   "outputs": [],
   "source": [
    "df = rating_df.copy()\n",
    "df['userId'] = df['userId'].astype(int)\n",
    "df['movieId'] = df['movieId'].astype(int)\n",
    "df = df.join(movies_df, on='movieId', rsuffix='_movie_df')\n",
    "df.sort_values(by=['trend'], inplace=True, ascending=False)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make note of the missing number of movies from the ratings dataset. These are missing for a couple reasons: \n",
    "- Initial dataset used had invalid ids (from the movielens datasset) - Most likely\n",
    "- Movies have been deleted from the Recommender database - Likely\n",
    "- Incorrect datatypes - Unlikely but possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.075958Z",
     "iopub.status.busy": "2022-09-21T17:06:10.075767Z",
     "iopub.status.idle": "2022-09-21T17:06:10.085651Z",
     "shell.execute_reply": "2022-09-21T17:06:10.085017Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.075943Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_data = df[df['movieIdx'].isna()]\n",
    "\n",
    "number_of_missing_movies = len(missing_data.movieId.unique().tolist())\n",
    "print(number_of_missing_movies, 'movie ids missing that were rated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `NaN` columns that lack a `movieIdx` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.086700Z",
     "iopub.status.busy": "2022-09-21T17:06:10.086512Z",
     "iopub.status.idle": "2022-09-21T17:06:10.111342Z",
     "shell.execute_reply": "2022-09-21T17:06:10.110841Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.086686Z"
    }
   },
   "outputs": [],
   "source": [
    "training_df = df.copy().dropna()\n",
    "training_df['movieIdx'] = training_df['movieIdx'].astype(int)\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.112412Z",
     "iopub.status.busy": "2022-09-21T17:06:10.112233Z",
     "iopub.status.idle": "2022-09-21T17:06:10.129617Z",
     "shell.execute_reply": "2022-09-21T17:06:10.129112Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.112397Z"
    }
   },
   "outputs": [],
   "source": [
    "user_ids = training_df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "\n",
    "\n",
    "movie_ids = training_df[\"movieIdx\"].unique().tolist()\n",
    "\n",
    "df = training_df.copy()\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieIdx\"]\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_ids)\n",
    "\n",
    "df[\"rating\"] = training_df[\"rating\"].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.130513Z",
     "iopub.status.busy": "2022-09-21T17:06:10.130312Z",
     "iopub.status.idle": "2022-09-21T17:06:10.153283Z",
     "shell.execute_reply": "2022-09-21T17:06:10.152775Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.130497Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.154113Z",
     "iopub.status.busy": "2022-09-21T17:06:10.153932Z",
     "iopub.status.idle": "2022-09-21T17:06:10.201159Z",
     "shell.execute_reply": "2022-09-21T17:06:10.200590Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.154098Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, multiply, concatenate, Flatten, Input, Dense\n",
    "from tensorflow.keras import optimizers as opt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_SIZE = 500\n",
    "num_unique_users = num_users\n",
    "num_unique_movies = num_movies\n",
    "users_input = Input(shape=(1,), name=\"users_input\")\n",
    "users_embedding = Embedding(num_unique_users + 1, EMBEDDING_SIZE, name=\"users_embeddings\")(users_input)\n",
    "users_bias = Embedding(num_unique_users + 1, 1, name=\"users_bias\")(users_input)\n",
    "\n",
    "movies_input = Input(shape=(1,), name=\"movies_input\")\n",
    "movies_embedding = Embedding(num_unique_movies + 1, EMBEDDING_SIZE, name=\"movies_embedding\")(movies_input)\n",
    "movies_bias = Embedding(num_unique_movies + 1, 1, name=\"movies_bias\")(movies_input)\n",
    "\n",
    "dot_product_users_movies = multiply([users_embedding, movies_embedding])\n",
    "input_terms = dot_product_users_movies + users_bias + movies_bias\n",
    "input_terms = Flatten(name=\"fl_inputs\")(input_terms)\n",
    "# output = Dense(1, activation=\"relu\", name=\"output\")(input_terms) \n",
    "\n",
    "output = Dense(1, activation=\"sigmoid\", name=\"output\")(input_terms) \n",
    "output = output * (max_rating - min_rating) + min_rating\n",
    "\n",
    "\n",
    "model = Model(inputs=[users_input, movies_input], outputs=output)\n",
    "\n",
    "opt_adam = opt.Adam(learning_rate = 0.005)\n",
    "model.compile(optimizer=opt_adam, loss= ['mse'], metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:07:27.863315Z",
     "iopub.status.busy": "2022-09-21T17:07:27.862678Z",
     "iopub.status.idle": "2022-09-21T17:07:27.883267Z",
     "shell.execute_reply": "2022-09-21T17:07:27.882685Z",
     "shell.execute_reply.started": "2022-09-21T17:07:27.863292Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:10.202063Z",
     "iopub.status.busy": "2022-09-21T17:06:10.201888Z",
     "iopub.status.idle": "2022-09-21T17:06:10.224755Z",
     "shell.execute_reply": "2022-09-21T17:06:10.224197Z",
     "shell.execute_reply.started": "2022-09-21T17:06:10.202048Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, random_state=42, test_size=0.2, stratify=df.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:06:50.781014Z",
     "iopub.status.busy": "2022-09-21T17:06:50.780612Z",
     "iopub.status.idle": "2022-09-21T17:07:02.851920Z",
     "shell.execute_reply": "2022-09-21T17:07:02.851282Z",
     "shell.execute_reply.started": "2022-09-21T17:06:50.780993Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=[df_train.user.to_numpy(), df_train.movie.to_numpy()],\n",
    "    y=df_train.rating.to_numpy(),\n",
    "    batch_size=200,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=([df_val.user.to_numpy(), df_val.movie.to_numpy()],df_val.rating.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:32.391219Z",
     "iopub.status.busy": "2022-09-21T17:13:32.390726Z",
     "iopub.status.idle": "2022-09-21T17:13:32.445178Z",
     "shell.execute_reply": "2022-09-21T17:13:32.444683Z",
     "shell.execute_reply.started": "2022-09-21T17:13:32.391197Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_preds = 100\n",
    "movies = df.sample(n=number_of_preds).movie.to_list()\n",
    "user_list = df.sample(n=1).user.to_list() * number_of_preds\n",
    "use_id = False\n",
    "if use_id:\n",
    "    user_list = [user2user_encoded.get(1)] * number_of_preds\n",
    "preds = model.predict(x=[np.array(user_list), np.array(movies)])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:46.311869Z",
     "iopub.status.busy": "2022-09-21T17:13:46.311258Z",
     "iopub.status.idle": "2022-09-21T17:13:46.321652Z",
     "shell.execute_reply": "2022-09-21T17:13:46.321048Z",
     "shell.execute_reply.started": "2022-09-21T17:13:46.311846Z"
    }
   },
   "outputs": [],
   "source": [
    "suggestions = []\n",
    "user_id = userencoded2user.get(user_list[0])\n",
    "\n",
    "suggestions_df = movies_df.copy()[movies_df['movieIdx'].isin(movies)]\n",
    "suggestions_df['userId'] = user_id\n",
    "\n",
    "suggestions_df['score'] = suggestions_df['movieIdx'].apply(lambda x: preds[movies.index(x)][0])\n",
    "\n",
    "for i, movieIdx in enumerate(movies):\n",
    "    pred_rank = preds[i][0]\n",
    "    print(user_id, movieIdx, pred_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:47.821071Z",
     "iopub.status.busy": "2022-09-21T17:13:47.820572Z",
     "iopub.status.idle": "2022-09-21T17:13:47.829043Z",
     "shell.execute_reply": "2022-09-21T17:13:47.828514Z",
     "shell.execute_reply.started": "2022-09-21T17:13:47.821050Z"
    }
   },
   "outputs": [],
   "source": [
    "user_ratings = rating_df.copy()[rating_df.userId == suggestions_df.userId.tolist()[0]]\n",
    "user_ratings.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T17:13:48.490239Z",
     "iopub.status.busy": "2022-09-21T17:13:48.489743Z",
     "iopub.status.idle": "2022-09-21T17:13:48.498857Z",
     "shell.execute_reply": "2022-09-21T17:13:48.498307Z",
     "shell.execute_reply.started": "2022-09-21T17:13:48.490217Z"
    }
   },
   "outputs": [],
   "source": [
    "suggestions_df.sort_values(by=['score'], inplace=True, ascending=False)\n",
    "suggestions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec64b31cc60f70e8dab7346c6ae7185d9efc964eeeacbce2cf14a9d83453e877"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
